{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST convolutional neural networks with batch norm and regularizer\n",
    "\n",
    "* MNIST data를 가지고 softmax classifier를 만들어보자.\n",
    "* train data, validation data를 구분하여 model을 training하자\n",
    "  + train data : model을 training 시키는 데 사용\n",
    "  + validation data : training에 이용하지않은 data, model을 validation 하는 데 활용 (보통 1 epoch마다)\n",
    "* batch normalization과 l2 regularizer를 추가!\n",
    "* [`tf.contrib.slim`](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) 참고\n",
    "* [05_mnist_cnn_with_train_validation_split.ipynb](https://nbviewer.jupyter.org/github/modulabs/modu-tensorflow/blob/master/week03/05_mnist_cnn_with_train_validation_split.ipynb)를 기반으로 refactoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A LeNet-5 like cnn MNIST classifier.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "\n",
    "#np.random.seed(219)\n",
    "#tf.set_random_seed(219)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data from tf.keras\n",
    "(x_train, y_train), (x_test, y_test) = \\\n",
    "    tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_train = x_train.astype(dtype = np.float32)\n",
    "y_train = np.asarray(y_train, dtype=np.int32)\n",
    "\n",
    "x_test = x_test / 255.\n",
    "x_test = x_test.astype(np.float32)\n",
    "y_test = np.asarray(y_test, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training (50000, 28, 28), (50000,)\n",
      "for validation (10000, 28, 28), (10000,)\n"
     ]
    }
   ],
   "source": [
    "# x_train에서 training에 쓸 index 50000개 가져옴\n",
    "tr_indices = np.random.choice(np.arange(x_train.shape[0]), size = 50000, replace = False)\n",
    "\n",
    "# model training에 이용할 data\n",
    "x_tr = x_train[tr_indices]\n",
    "y_tr = y_train[tr_indices]\n",
    "\n",
    "# epoch 마다 model validation에 이용할 data\n",
    "x_val = np.delete(arr = x_train, obj = tr_indices, axis = 0)\n",
    "y_val = np.delete(arr = y_train, obj = tr_indices, axis = 0)\n",
    "\n",
    "print('for training {}, {}'.format(x_tr.shape, y_tr.shape))\n",
    "print('for validation {}, {}'.format(x_val.shape, y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up dataset with `tf.data`\n",
    "\n",
    "#### create input pipeline with `tf.data.Dataset` to train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((?, 28, 28), (?,)), types: (tf.float32, tf.int32)>\n",
      "<BatchDataset shapes: ((?, 28, 28), (?,)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# for training\n",
    "tr_dataset = tf.data.Dataset.from_tensor_slices((x_tr, y_tr))\n",
    "tr_dataset = tr_dataset.shuffle(buffer_size = 10000)\n",
    "tr_dataset = tr_dataset.batch(batch_size = batch_size)\n",
    "tr_iterator = tr_dataset.make_initializable_iterator()\n",
    "\n",
    "print(tr_dataset)\n",
    "\n",
    "# for validation\n",
    "# validation data의 용량이 in memory에 넣을 수 없을정도로 아래와 같이 활용한다.\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.shuffle(buffer_size = 10000)\n",
    "val_dataset = val_dataset.batch(batch_size = batch_size)\n",
    "val_iterator = val_dataset.make_initializable_iterator()\n",
    "\n",
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data.Iterator.from_string_handle의 output_shapes는 default = None이지만 꼭 값을 넣는 게 좋음\n",
    "handle = tf.placeholder(tf.string)\n",
    "iterator = tf.data.Iterator.from_string_handle(handle,\n",
    "                                               tr_dataset.output_types,\n",
    "                                               tr_dataset.output_shapes)\n",
    "x, y = iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(x):\n",
    "    \"\"\"\"Model function for CNN.\n",
    "    Args:\n",
    "        x: input images\n",
    "        mode: boolean whether trainig mode or test mode\n",
    "    Returns:\n",
    "    logits: unnormalized score funtion\n",
    "  \"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "    # MNIST images are 28x28 pixels, and have one color channel\n",
    "\n",
    "    # batch normalization 적용 여부를 control하기위한 placeholder \n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    \n",
    "    with tf.name_scope('reshape'):\n",
    "        x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    \n",
    "    # slim.arg_scope를 이용하여, slim.conv2d, slim.fully_connected 함수의 default로 batch norm과\n",
    "    # l2 regularizer를 설정 (scale = 0.3)\n",
    "    \n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                         weights_regularizer = slim.l2_regularizer(scale = .3),\n",
    "                         normalizer_fn = slim.batch_norm,\n",
    "                         normalizer_params = {'decay' : .9, 'is_training': is_training}):\n",
    "        # Convolutional Layer #1\n",
    "        # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "        # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "        conv1 = slim.conv2d(x_image, 32, [5, 5], scope='conv1')\n",
    "\n",
    "        # Pooling Layer #1\n",
    "        # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "        # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "        pool1 = slim.max_pool2d(conv1, [2, 2], scope='pool1')\n",
    "  \n",
    "        # Convolutional Layer #2\n",
    "        # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "        # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "        conv2 = slim.conv2d(pool1, 64, [5, 5], scope='conv2')\n",
    "\n",
    "        # Pooling Layer #2\n",
    "        # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "        # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "        # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "        pool2 = slim.max_pool2d(conv2, [2, 2], scope='pool2')\n",
    "\n",
    "        # Flatten tensor into a batch of vectors\n",
    "        # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "        # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "        pool2_flat = slim.flatten(pool2, scope='flatten')\n",
    "  \n",
    "        # Fully connected Layer\n",
    "        # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "        # Output Tensor Shape: [batch_size, 1024]\n",
    "        fc1 = slim.fully_connected(pool2_flat, 1024, scope='fc1')\n",
    "\n",
    "        # Logits layer\n",
    "        # Input Tensor Shape: [batch_size, 1024]\n",
    "        # Output Tensor Shape: [batch_size, 10]\n",
    "        logits = slim.fully_connected(fc1, 10, activation_fn=None, normalizer_fn = None,\n",
    "                                      normalizer_params = None,\n",
    "                                      scope='logits')\n",
    "  \n",
    "    return logits, is_training, x_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, is_training, x_image = cnn_model_fn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits))\n",
    "\n",
    "# tf.get_collection과 tf.GraphKeys.REGULARIZATION_LOSSES를 이용하여, regularization loss를 가져옴\n",
    "reg_term = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "total_loss = cross_entropy + reg_term\n",
    "\n",
    "# loss를 계산하기전 training의 경우, mini-batch 당 mean과 variance를 계산해야하고, \n",
    "# validation의 경우 training시 mini-batch당 가지고 있던 mean과 variance를 exponential moving average를 이용하여\n",
    "# average한 것을 가지고 있다가 이용해야함. 아래의 코드가 그 기능을 함\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(control_inputs = update_ops):\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.Session()` and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs :   1, tr_loss : 20.957, val_loss : 0.460\n",
      "epochs :   2, tr_loss : 0.410, val_loss : 0.393\n",
      "epochs :   3, tr_loss : 0.362, val_loss : 0.309\n",
      "epochs :   4, tr_loss : 0.342, val_loss : 0.316\n",
      "epochs :   5, tr_loss : 0.333, val_loss : 0.309\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config=sess_config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# history\n",
    "tr_hist = []\n",
    "val_hist = []\n",
    "\n",
    "# Generate handles of tr_iterator and val_iterator\n",
    "tr_handle, val_handle = sess.run(fetches = [tr_iterator.string_handle(), val_iterator.string_handle()])\n",
    "\n",
    "# Train\n",
    "max_epochs = 5\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    \n",
    "    avg_tr_loss = 0\n",
    "    avg_val_loss = 0\n",
    "    tr_step = 0\n",
    "    val_step = 0\n",
    "    \n",
    "    # training 1-epoch\n",
    "    sess.run(tr_iterator.initializer)\n",
    "    while True:\n",
    "        try:\n",
    "            _, tr_loss = sess.run(fetches = [train_step, total_loss],\n",
    "                               feed_dict = {handle : tr_handle, is_training : True})\n",
    "            tr_step += 1\n",
    "            avg_tr_loss += tr_loss\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    \n",
    "    # validation 1-epoch\n",
    "    sess.run(val_iterator.initializer)\n",
    "    while True:\n",
    "        try:\n",
    "            val_loss = sess.run(total_loss, \n",
    "                                feed_dict = {handle : val_handle, is_training : False})\n",
    "            val_step += 1\n",
    "            avg_val_loss += val_loss\n",
    "        \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "            \n",
    "    avg_tr_loss /= tr_step\n",
    "    avg_val_loss /= val_step\n",
    "    tr_hist.append(avg_tr_loss)\n",
    "    val_hist.append(avg_val_loss)\n",
    "    \n",
    "    print('epochs : {:3}, tr_loss : {:.3f}, val_loss : {:.3f}'.format(epoch + 1, avg_tr_loss, avg_val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = sess.run(logits, feed_dict = {x : x_test, is_training : False})\n",
    "yhat = np.argmax(yhat, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 98.35%\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy : {:.2%}'.format(np.mean(yhat == y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1037e66a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_hist, label = 'train')\n",
    "plt.plot(val_hist, label = 'validation')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

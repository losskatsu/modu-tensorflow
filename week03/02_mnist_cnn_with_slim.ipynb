{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST convolutional neural networks with slim\n",
    "\n",
    "* MNIST data를 가지고 softmax classifier를 만들어보자.\n",
    "* [`tf.contrib.slim`](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\envs\\tensorflow_1_7\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"A very simple MNIST classifier.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "\n",
    "np.random.seed(219)\n",
    "tf.set_random_seed(219)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "    tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "train_labels = np.asarray(train_labels, dtype=np.int32)\n",
    "\n",
    "test_data = test_data / 255.\n",
    "test_labels = np.asarray(test_labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = 500\n",
    "print(\"label = {}\".format(train_labels[index]))\n",
    "plt.imshow(train_data[index].reshape(28, 28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up dataset with `tf.data`\n",
    "\n",
    "#### create input pipeline with `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((?, 28, 28), (?,)), types: (tf.float64, tf.int32)>\n",
      "<BatchDataset shapes: ((?, 28, 28), (?,)), types: (tf.float64, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# for train\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size = 10000)\n",
    "train_dataset = train_dataset.batch(batch_size = batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "# for test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "test_dataset = test_dataset.shuffle(buffer_size = 10000)\n",
    "test_dataset = test_dataset.batch(batch_size = len(test_data))\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data.Iterator.from_string_handle의 output_shapes는 default = None이지만 꼭 값을 넣는 게 좋음\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(handle,\n",
    "                                               train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "x, y = iterator.get_next()\n",
    "x = tf.cast(x, dtype = tf.float32)\n",
    "y = tf.cast(y, dtype = tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.contrib.slim`\n",
    "\n",
    "```python\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# pylint: disable=unused-import,line-too-long,g-importing-member,wildcard-import\n",
    "# TODO(jart): Delete non-slim imports\n",
    "from tensorflow.contrib import losses\n",
    "from tensorflow.contrib import metrics\n",
    "from tensorflow.contrib.framework.python.ops.arg_scope import *\n",
    "from tensorflow.contrib.framework.python.ops.variables import *\n",
    "from tensorflow.contrib.layers.python.layers import *\n",
    "from tensorflow.contrib.layers.python.layers.initializers import *\n",
    "from tensorflow.contrib.layers.python.layers.regularizers import *\n",
    "from tensorflow.contrib.slim.python.slim import evaluation\n",
    "from tensorflow.contrib.slim.python.slim import learning\n",
    "from tensorflow.contrib.slim.python.slim import model_analyzer\n",
    "from tensorflow.contrib.slim.python.slim import queues\n",
    "from tensorflow.contrib.slim.python.slim import summaries\n",
    "from tensorflow.contrib.slim.python.slim.data import data_decoder\n",
    "from tensorflow.contrib.slim.python.slim.data import data_provider\n",
    "from tensorflow.contrib.slim.python.slim.data import dataset\n",
    "from tensorflow.contrib.slim.python.slim.data import dataset_data_provider\n",
    "from tensorflow.contrib.slim.python.slim.data import parallel_reader\n",
    "from tensorflow.contrib.slim.python.slim.data import prefetch_queue\n",
    "from tensorflow.contrib.slim.python.slim.data import tfexample_decoder\n",
    "from tensorflow.python.util.all_util import make_all\n",
    "# pylint: enable=unused-import,line-too-long,g-importing-member,wildcard-import\n",
    "\n",
    "__all__ = make_all(__name__)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between [`tf.layers`](https://www.tensorflow.org/api_docs/python/tf/layers) and [`tf.contrib.layers`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers)\n",
    "\n",
    "#### [`tf.layers.conv2d()`](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)\n",
    "```python\n",
    "tf.layers.conv2d(\n",
    "    inputs,\n",
    "    filters,\n",
    "    kernel_size,\n",
    "    strides=(1, 1),\n",
    "    padding='valid',\n",
    "    data_format='channels_last',\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer=None,\n",
    "    bias_initializer=tf.zeros_initializer(),\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    trainable=True,\n",
    "    name=None,\n",
    "    reuse=None\n",
    ")\n",
    "```\n",
    "\n",
    "#### [`slim.conv2d()`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/conv2d)\n",
    "```python\n",
    "tf.contrib.layers.conv2d(\n",
    "    inputs,\n",
    "    num_outputs,\n",
    "    kernel_size,\n",
    "    stride=1,\n",
    "    padding='SAME',\n",
    "    data_format=None,\n",
    "    rate=1,\n",
    "    activation_fn=tf.nn.relu,\n",
    "    normalizer_fn=None,\n",
    "    normalizer_params=None,\n",
    "    weights_initializer=initializers.xavier_initializer(),\n",
    "    weights_regularizer=None,\n",
    "    biases_initializer=tf.zeros_initializer(),\n",
    "    biases_regularizer=None,\n",
    "    reuse=None,\n",
    "    variables_collections=None,\n",
    "    outputs_collections=None,\n",
    "    trainable=True,\n",
    "    scope=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(x):\n",
    "  \"\"\"Model function for CNN.\n",
    "  Args:\n",
    "    x: input images\n",
    "    mode: boolean whether trainig mode or test mode\n",
    "    \n",
    "  Returns:\n",
    "    logits: unnormalized score funtion\n",
    "  \"\"\"\n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  # MNIST images are 28x28 pixels, and have one color channel\n",
    "  with tf.name_scope('reshape'):\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "  # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  # 여기를 직접 채워 넣으시면 됩니다.\n",
    "  conv1 = slim.conv2d(x_image, 32, kernel_size=5, stride=1, padding='SAME', activation_fn=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  # 여기를 직접 채워 넣으시면 됩니다.\n",
    "  pool1 = slim.max_pool2d(conv1, 2)\n",
    "  \n",
    "  # Convolutional Layer #2\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  # 여기를 직접 채워 넣으시면 됩니다.\n",
    "  conv2 = slim.conv2d(pool1, 64, kernel_size=5, stride=1, padding='SAME', activation_fn=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #2\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  # 여기를 직접 채워 넣으시면 됩니다.\n",
    "  pool2 = slim.max_pool2d(conv1, 2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  # 여기를 직접 채워 넣으시면 됩니다.\n",
    "  pool2_flat = slim.flatten(pool2)\n",
    "  \n",
    "  # Fully connected Layer\n",
    "  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "  # 여기를 직접 채워 넣으시면 됩니다.\n",
    "  fc1 = slim.fully_connected(pool2_flat, 1024)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "  is_training = tf.placeholder(tf.bool)\n",
    "  # 여기를 직접 채워 넣으시면 됩니다.\n",
    "  fc1_drop = slim.dropout(fc1, keep_prob=0.6, is_training=is_training)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 10]\n",
    "  # 여기를 직접 채워 넣으시면 됩니다.\n",
    "  logits = slim.fully_connected(fc1_drop, 10)\n",
    "  \n",
    "  return logits, is_training, x_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, is_training, x_image = cnn_model_fn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기를 직접 채워 넣으시면 됩니다.\n",
    "cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign `tf.summary.FileWriter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph to: graphs/02_mnist_cnn_with_slim\n"
     ]
    }
   ],
   "source": [
    "graph_location = 'graphs/02_mnist_cnn_with_slim'\n",
    "print('Saving graph to: %s' % graph_location)\n",
    "train_writer = tf.summary.FileWriter(graph_location)\n",
    "train_writer.add_graph(tf.get_default_graph()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.summary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('summaries'):\n",
    "  tf.summary.scalar('loss/cross_entropy', cross_entropy)\n",
    "  tf.summary.image('images', x_image)\n",
    "  for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.op.name, var)\n",
    "  # merge all summaries\n",
    "  summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.Session()` and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 2.3003\n",
      "step: 10, loss: 2.2633\n",
      "step: 20, loss: 2.24907\n",
      "step: 30, loss: 1.996\n",
      "step: 40, loss: 1.9126\n",
      "step: 50, loss: 1.77796\n",
      "step: 60, loss: 1.20221\n",
      "step: 70, loss: 1.37396\n",
      "step: 80, loss: 1.42507\n",
      "step: 90, loss: 1.16146\n",
      "step: 100, loss: 0.983938\n",
      "step: 110, loss: 1.38483\n",
      "step: 120, loss: 0.858056\n",
      "step: 130, loss: 1.09288\n",
      "step: 140, loss: 0.760726\n",
      "step: 150, loss: 0.935444\n",
      "step: 160, loss: 0.737615\n",
      "step: 170, loss: 0.801839\n",
      "step: 180, loss: 0.592394\n",
      "step: 190, loss: 0.713155\n",
      "step: 200, loss: 0.711996\n",
      "step: 210, loss: 1.16026\n",
      "step: 220, loss: 0.479807\n",
      "step: 230, loss: 0.730622\n",
      "step: 240, loss: 0.513967\n",
      "step: 250, loss: 0.59203\n",
      "step: 260, loss: 0.538492\n",
      "step: 270, loss: 0.294367\n",
      "step: 280, loss: 0.769381\n",
      "step: 290, loss: 0.690269\n",
      "step: 300, loss: 0.475494\n",
      "step: 310, loss: 0.48185\n",
      "step: 320, loss: 0.501347\n",
      "step: 330, loss: 0.710933\n",
      "step: 340, loss: 0.641737\n",
      "step: 350, loss: 0.517447\n",
      "step: 360, loss: 0.557723\n",
      "step: 370, loss: 0.268069\n",
      "step: 380, loss: 0.352454\n",
      "step: 390, loss: 0.618209\n",
      "step: 400, loss: 0.271084\n",
      "step: 410, loss: 0.543864\n",
      "step: 420, loss: 0.774164\n",
      "step: 430, loss: 0.635921\n",
      "step: 440, loss: 0.596773\n",
      "step: 450, loss: 0.752125\n",
      "step: 460, loss: 0.444915\n",
      "step: 470, loss: 0.665047\n",
      "step: 480, loss: 0.630632\n",
      "step: 490, loss: 0.30988\n",
      "step: 500, loss: 0.528689\n",
      "step: 510, loss: 0.903132\n",
      "step: 520, loss: 0.511192\n",
      "step: 530, loss: 0.681923\n",
      "step: 540, loss: 0.314935\n",
      "step: 550, loss: 0.521229\n",
      "step: 560, loss: 0.242333\n",
      "step: 570, loss: 0.48572\n",
      "step: 580, loss: 0.659515\n",
      "step: 590, loss: 0.555678\n",
      "step: 600, loss: 0.402821\n",
      "step: 610, loss: 0.340124\n",
      "step: 620, loss: 0.561784\n",
      "step: 630, loss: 0.377745\n",
      "step: 640, loss: 0.27057\n",
      "step: 650, loss: 0.605321\n",
      "step: 660, loss: 0.445875\n",
      "step: 670, loss: 0.446695\n",
      "step: 680, loss: 0.268208\n",
      "step: 690, loss: 0.454467\n",
      "step: 700, loss: 0.501985\n",
      "step: 710, loss: 0.426905\n",
      "step: 720, loss: 0.560342\n",
      "step: 730, loss: 0.659713\n",
      "step: 740, loss: 0.503795\n",
      "step: 750, loss: 0.627613\n",
      "step: 760, loss: 0.330541\n",
      "step: 770, loss: 0.572757\n",
      "step: 780, loss: 0.281877\n",
      "step: 790, loss: 0.162724\n",
      "step: 800, loss: 0.658216\n",
      "step: 810, loss: 0.395147\n",
      "step: 820, loss: 0.491367\n",
      "step: 830, loss: 0.433268\n",
      "step: 840, loss: 0.615047\n",
      "step: 850, loss: 0.496804\n",
      "step: 860, loss: 0.747323\n",
      "step: 870, loss: 0.488598\n",
      "step: 880, loss: 0.28831\n",
      "step: 890, loss: 0.193705\n",
      "step: 900, loss: 0.555782\n",
      "step: 910, loss: 0.218883\n",
      "step: 920, loss: 0.394458\n",
      "step: 930, loss: 0.507265\n",
      "step: 940, loss: 0.466844\n",
      "step: 950, loss: 0.516972\n",
      "step: 960, loss: 0.228308\n",
      "step: 970, loss: 0.446877\n",
      "step: 980, loss: 0.476485\n",
      "step: 990, loss: 0.34935\n",
      "step: 1000, loss: 0.572946\n",
      "step: 1010, loss: 0.415962\n",
      "step: 1020, loss: 0.325949\n",
      "step: 1030, loss: 0.482075\n",
      "step: 1040, loss: 0.325389\n",
      "step: 1050, loss: 0.532038\n",
      "step: 1060, loss: 0.358568\n",
      "step: 1070, loss: 0.635597\n",
      "step: 1080, loss: 0.591557\n",
      "step: 1090, loss: 0.126358\n",
      "step: 1100, loss: 0.534136\n",
      "step: 1110, loss: 0.394972\n",
      "step: 1120, loss: 0.421966\n",
      "step: 1130, loss: 0.534973\n",
      "step: 1140, loss: 0.513143\n",
      "step: 1150, loss: 0.548386\n",
      "step: 1160, loss: 0.355515\n",
      "step: 1170, loss: 0.111626\n",
      "step: 1180, loss: 0.515558\n",
      "step: 1190, loss: 0.235483\n",
      "step: 1200, loss: 0.572253\n",
      "step: 1210, loss: 0.543011\n",
      "step: 1220, loss: 0.467316\n",
      "step: 1230, loss: 0.545054\n",
      "step: 1240, loss: 0.529666\n",
      "step: 1250, loss: 0.339534\n",
      "step: 1260, loss: 0.18531\n",
      "step: 1270, loss: 0.204853\n",
      "step: 1280, loss: 0.248302\n",
      "step: 1290, loss: 0.531821\n",
      "step: 1300, loss: 0.350802\n",
      "step: 1310, loss: 0.24152\n",
      "step: 1320, loss: 0.304358\n",
      "step: 1330, loss: 0.507485\n",
      "step: 1340, loss: 0.317748\n",
      "step: 1350, loss: 0.248591\n",
      "step: 1360, loss: 0.459739\n",
      "step: 1370, loss: 0.506702\n",
      "step: 1380, loss: 0.359851\n",
      "step: 1390, loss: 0.322015\n",
      "step: 1400, loss: 0.126021\n",
      "step: 1410, loss: 0.203368\n",
      "step: 1420, loss: 0.202434\n",
      "step: 1430, loss: 0.292322\n",
      "step: 1440, loss: 0.800637\n",
      "step: 1450, loss: 0.299675\n",
      "step: 1460, loss: 0.206212\n",
      "step: 1470, loss: 0.363073\n",
      "step: 1480, loss: 0.338105\n",
      "step: 1490, loss: 0.366787\n",
      "step: 1500, loss: 0.322126\n",
      "step: 1510, loss: 0.525316\n",
      "step: 1520, loss: 0.329404\n",
      "step: 1530, loss: 0.209879\n",
      "step: 1540, loss: 0.358573\n",
      "step: 1550, loss: 0.223707\n",
      "step: 1560, loss: 0.229356\n",
      "step: 1570, loss: 0.519133\n",
      "step: 1580, loss: 0.365092\n",
      "step: 1590, loss: 0.353871\n",
      "step: 1600, loss: 0.380854\n",
      "step: 1610, loss: 0.250632\n",
      "step: 1620, loss: 0.333622\n",
      "step: 1630, loss: 0.448999\n",
      "step: 1640, loss: 0.586417\n",
      "step: 1650, loss: 0.394464\n",
      "step: 1660, loss: 0.259444\n",
      "step: 1670, loss: 0.47048\n",
      "step: 1680, loss: 0.44261\n",
      "step: 1690, loss: 0.0325598\n",
      "step: 1700, loss: 0.334736\n",
      "End of dataset\n",
      "Epochs: 0 Elapsed time: 63.99510598182678\n",
      "step: 1710, loss: 0.274354\n",
      "step: 1720, loss: 0.525904\n",
      "step: 1730, loss: 0.324941\n",
      "step: 1740, loss: 0.597873\n",
      "step: 1750, loss: 0.52913\n",
      "step: 1760, loss: 0.554474\n",
      "step: 1770, loss: 0.166143\n",
      "step: 1780, loss: 0.591368\n",
      "step: 1790, loss: 0.170253\n",
      "step: 1800, loss: 0.328261\n",
      "step: 1810, loss: 0.21074\n",
      "step: 1820, loss: 0.505025\n",
      "step: 1830, loss: 0.370482\n",
      "step: 1840, loss: 0.353469\n",
      "step: 1850, loss: 0.289746\n",
      "step: 1860, loss: 0.214092\n",
      "step: 1870, loss: 0.58819\n",
      "step: 1880, loss: 0.336009\n",
      "step: 1890, loss: 0.216089\n",
      "step: 1900, loss: 0.3055\n",
      "step: 1910, loss: 0.41887\n",
      "step: 1920, loss: 0.283003\n",
      "step: 1930, loss: 0.110305\n",
      "step: 1940, loss: 0.109026\n",
      "step: 1950, loss: 0.361896\n",
      "step: 1960, loss: 0.571072\n",
      "step: 1970, loss: 0.327636\n",
      "step: 1980, loss: 0.337949\n",
      "step: 1990, loss: 0.306988\n",
      "step: 2000, loss: 0.300105\n",
      "step: 2010, loss: 0.36345\n",
      "step: 2020, loss: 0.61254\n",
      "step: 2030, loss: 0.675656\n",
      "step: 2040, loss: 0.150129\n",
      "step: 2050, loss: 0.173676\n",
      "step: 2060, loss: 0.374394\n",
      "step: 2070, loss: 0.474007\n",
      "step: 2080, loss: 0.54529\n",
      "step: 2090, loss: 0.356082\n",
      "step: 2100, loss: 0.309318\n",
      "step: 2110, loss: 0.269633\n",
      "step: 2120, loss: 0.23313\n",
      "step: 2130, loss: 0.393557\n",
      "step: 2140, loss: 0.173898\n",
      "step: 2150, loss: 0.187999\n",
      "step: 2160, loss: 0.61525\n",
      "step: 2170, loss: 0.231723\n",
      "step: 2180, loss: 0.514852\n",
      "step: 2190, loss: 0.144905\n",
      "step: 2200, loss: 0.387397\n",
      "step: 2210, loss: 0.497696\n",
      "step: 2220, loss: 0.286053\n",
      "step: 2230, loss: 0.318839\n",
      "step: 2240, loss: 0.337815\n",
      "step: 2250, loss: 0.176975\n",
      "step: 2260, loss: 0.308576\n",
      "step: 2270, loss: 0.616298\n",
      "step: 2280, loss: 0.417093\n",
      "step: 2290, loss: 0.481662\n",
      "step: 2300, loss: 0.229925\n",
      "step: 2310, loss: 0.0854258\n",
      "step: 2320, loss: 0.0207912\n",
      "step: 2330, loss: 0.531268\n",
      "step: 2340, loss: 0.231834\n",
      "step: 2350, loss: 0.424352\n",
      "step: 2360, loss: 0.359089\n",
      "step: 2370, loss: 0.461664\n",
      "step: 2380, loss: 0.198723\n",
      "step: 2390, loss: 0.190672\n",
      "step: 2400, loss: 0.245907\n",
      "step: 2410, loss: 0.328639\n",
      "step: 2420, loss: 0.324512\n",
      "step: 2430, loss: 0.327456\n",
      "step: 2440, loss: 0.425902\n",
      "step: 2450, loss: 0.32324\n",
      "step: 2460, loss: 0.327691\n",
      "step: 2470, loss: 0.273942\n",
      "step: 2480, loss: 0.115873\n",
      "step: 2490, loss: 0.389248\n",
      "step: 2500, loss: 0.497101\n",
      "step: 2510, loss: 0.316013\n",
      "step: 2520, loss: 0.258965\n",
      "step: 2530, loss: 0.391592\n",
      "step: 2540, loss: 0.41052\n",
      "step: 2550, loss: 0.426351\n",
      "step: 2560, loss: 0.255336\n",
      "step: 2570, loss: 0.307552\n",
      "step: 2580, loss: 0.419897\n",
      "step: 2590, loss: 0.287157\n",
      "step: 2600, loss: 0.319645\n",
      "step: 2610, loss: 0.350494\n",
      "step: 2620, loss: 0.173459\n",
      "step: 2630, loss: 0.150863\n",
      "step: 2640, loss: 0.245547\n",
      "step: 2650, loss: 0.50223\n",
      "step: 2660, loss: 0.472245\n",
      "step: 2670, loss: 0.132398\n",
      "step: 2680, loss: 0.196992\n",
      "step: 2690, loss: 0.295612\n",
      "step: 2700, loss: 0.43984\n",
      "step: 2710, loss: 0.371129\n",
      "step: 2720, loss: 0.434002\n",
      "step: 2730, loss: 0.245965\n",
      "step: 2740, loss: 0.311089\n",
      "step: 2750, loss: 0.391212\n",
      "step: 2760, loss: 0.679755\n",
      "step: 2770, loss: 0.621552\n",
      "step: 2780, loss: 0.573913\n",
      "step: 2790, loss: 0.0876475\n",
      "step: 2800, loss: 0.282821\n",
      "step: 2810, loss: 0.27831\n",
      "step: 2820, loss: 0.34403\n",
      "step: 2830, loss: 0.259214\n",
      "step: 2840, loss: 0.559784\n",
      "step: 2850, loss: 0.338959\n",
      "step: 2860, loss: 0.413681\n",
      "step: 2870, loss: 0.375541\n",
      "step: 2880, loss: 0.228445\n",
      "step: 2890, loss: 0.170879\n",
      "step: 2900, loss: 0.477727\n",
      "step: 2910, loss: 0.326199\n",
      "step: 2920, loss: 0.537847\n",
      "step: 2930, loss: 0.337312\n",
      "step: 2940, loss: 0.577611\n",
      "step: 2950, loss: 0.111197\n",
      "step: 2960, loss: 0.245559\n",
      "step: 2970, loss: 0.366934\n",
      "step: 2980, loss: 0.625492\n",
      "step: 2990, loss: 0.408479\n",
      "step: 3000, loss: 0.388901\n",
      "step: 3010, loss: 0.514254\n",
      "step: 3020, loss: 0.120911\n",
      "step: 3030, loss: 0.179178\n",
      "step: 3040, loss: 0.103544\n",
      "step: 3050, loss: 0.237591\n",
      "step: 3060, loss: 0.518199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3070, loss: 0.350894\n",
      "step: 3080, loss: 0.0462525\n",
      "step: 3090, loss: 0.324558\n",
      "step: 3100, loss: 0.391808\n",
      "step: 3110, loss: 0.249612\n",
      "step: 3120, loss: 0.221159\n",
      "step: 3130, loss: 0.575305\n",
      "step: 3140, loss: 0.319139\n",
      "step: 3150, loss: 0.34503\n",
      "step: 3160, loss: 0.64881\n",
      "step: 3170, loss: 0.386993\n",
      "step: 3180, loss: 0.157228\n",
      "step: 3190, loss: 0.291223\n",
      "step: 3200, loss: 0.721927\n",
      "step: 3210, loss: 0.103079\n",
      "step: 3220, loss: 0.21592\n",
      "step: 3230, loss: 0.267753\n",
      "step: 3240, loss: 0.313865\n",
      "step: 3250, loss: 0.388074\n",
      "step: 3260, loss: 0.29527\n",
      "step: 3270, loss: 0.210831\n",
      "step: 3280, loss: 0.254272\n",
      "step: 3290, loss: 0.231223\n",
      "step: 3300, loss: 0.520363\n",
      "step: 3310, loss: 0.240268\n",
      "step: 3320, loss: 0.254207\n",
      "step: 3330, loss: 0.259377\n",
      "step: 3340, loss: 0.684005\n",
      "step: 3350, loss: 0.576318\n",
      "step: 3360, loss: 0.314368\n",
      "step: 3370, loss: 0.148451\n",
      "step: 3380, loss: 0.271975\n",
      "step: 3390, loss: 0.354275\n",
      "step: 3400, loss: 0.154172\n",
      "End of dataset\n",
      "Epochs: 1 Elapsed time: 60.45431041717529\n",
      "training done!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "sess = tf.Session(config=sess_config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train_iterator\n",
    "train_iterator = train_dataset.make_initializable_iterator()\n",
    "train_handle = sess.run(train_iterator.string_handle())\n",
    "\n",
    "# Train\n",
    "max_epochs = 2\n",
    "step = 0\n",
    "for epochs in range(max_epochs):\n",
    "  # 여기를 직접 채워 넣으시면 됩니다.\n",
    "  sess.run(train_iterator.initializer)\n",
    "\n",
    "  start_time = time.time()\n",
    "  while True:\n",
    "    try:\n",
    "      # 여기를 직접 채워 넣으시면 됩니다.\n",
    "      _, loss = sess.run([train_step, cross_entropy], feed_dict={handle:train_handle, is_training:True})\n",
    "      if step % 10 == 0:\n",
    "        print(\"step: %d, loss: %g\" % (step, loss))\n",
    "        \n",
    "        # summary\n",
    "        summary_str = sess.run(summary_op, feed_dict={handle:train_handle, is_training:True})\n",
    "        train_writer.add_summary(summary_str, global_step=step)\n",
    "        \n",
    "      step += 1\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"End of dataset\")  # ==> \"End of dataset\"\n",
    "        break\n",
    "    \n",
    "  print(\"Epochs: {} Elapsed time: {}\".format(epochs, time.time() - start_time))\n",
    "\n",
    "train_writer.close()\n",
    "print(\"training done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_iterator\n",
    "test_iterator = test_dataset.make_initializable_iterator()\n",
    "test_handle = sess.run(test_iterator.string_handle())\n",
    "sess.run(test_iterator.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8825\n"
     ]
    }
   ],
   "source": [
    "accuracy, acc_op = tf.metrics.accuracy(labels=y, predictions=tf.argmax(logits, 1), name='accuracy')\n",
    "sess.run(tf.local_variables_initializer())\n",
    "\n",
    "sess.run(acc_op, feed_dict={handle: test_handle, is_training: False})\n",
    "print(\"test accuracy:\", sess.run(accuracy, feed_dict={handle: test_handle, is_training: False}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "test_batch_size = 16\n",
    "batch_index = np.random.choice(len(test_data), size=test_batch_size, replace=False)\n",
    "batch_xs = test_data[batch_index]\n",
    "y_pred = sess.run(logits, feed_dict={x: batch_xs, is_training: False})\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (px, py) in enumerate(zip(batch_xs, y_pred)):\n",
    "  p = fig.add_subplot(4, 8, i+1)\n",
    "  p.set_title(\"y_pred: {}\".format(np.argmax(py)))\n",
    "  p.imshow(px.reshape(28, 28), cmap='gray')\n",
    "  p.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 직접 실습\n",
    "\n",
    "* 여러가지 hyper-parameter들을 바꿔가면서 accuracy를 높혀보자"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST convolutional neural networks with slim\n",
    "\n",
    "* MNIST data를 가지고 softmax classifier를 만들어보자.\n",
    "* [`tf.contrib.slim`](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A LeNet-5 like cnn MNIST classifier.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "\n",
    "np.random.seed(219)\n",
    "tf.set_random_seed(219)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "    tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "train_labels = np.asarray(train_labels, dtype=np.int32)\n",
    "\n",
    "test_data = test_data / 255.\n",
    "test_labels = np.asarray(test_labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = 500\n",
    "print(\"label = {}\".format(train_labels[index]))\n",
    "plt.imshow(train_data[index].reshape(28, 28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up dataset with `tf.data`\n",
    "\n",
    "#### create input pipeline with `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((?, 28, 28), (?,)), types: (tf.float64, tf.int32)>\n",
      "<BatchDataset shapes: ((?, 28, 28), (?,)), types: (tf.float64, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# for train\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size = 10000)\n",
    "train_dataset = train_dataset.batch(batch_size = batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "# for test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "test_dataset = test_dataset.shuffle(buffer_size = 10000)\n",
    "test_dataset = test_dataset.batch(batch_size = len(test_data))\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data.Iterator.from_string_handle의 output_shapes는 default = None이지만 꼭 값을 넣는 게 좋음\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(handle,\n",
    "                                               train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "x, y = iterator.get_next()\n",
    "x = tf.cast(x, dtype = tf.float32)\n",
    "y = tf.cast(y, dtype = tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.contrib.slim`\n",
    "\n",
    "```python\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# pylint: disable=unused-import,line-too-long,g-importing-member,wildcard-import\n",
    "# TODO(jart): Delete non-slim imports\n",
    "from tensorflow.contrib import losses\n",
    "from tensorflow.contrib import metrics\n",
    "from tensorflow.contrib.framework.python.ops.arg_scope import *\n",
    "from tensorflow.contrib.framework.python.ops.variables import *\n",
    "from tensorflow.contrib.layers.python.layers import *\n",
    "from tensorflow.contrib.layers.python.layers.initializers import *\n",
    "from tensorflow.contrib.layers.python.layers.regularizers import *\n",
    "from tensorflow.contrib.slim.python.slim import evaluation\n",
    "from tensorflow.contrib.slim.python.slim import learning\n",
    "from tensorflow.contrib.slim.python.slim import model_analyzer\n",
    "from tensorflow.contrib.slim.python.slim import queues\n",
    "from tensorflow.contrib.slim.python.slim import summaries\n",
    "from tensorflow.contrib.slim.python.slim.data import data_decoder\n",
    "from tensorflow.contrib.slim.python.slim.data import data_provider\n",
    "from tensorflow.contrib.slim.python.slim.data import dataset\n",
    "from tensorflow.contrib.slim.python.slim.data import dataset_data_provider\n",
    "from tensorflow.contrib.slim.python.slim.data import parallel_reader\n",
    "from tensorflow.contrib.slim.python.slim.data import prefetch_queue\n",
    "from tensorflow.contrib.slim.python.slim.data import tfexample_decoder\n",
    "from tensorflow.python.util.all_util import make_all\n",
    "# pylint: enable=unused-import,line-too-long,g-importing-member,wildcard-import\n",
    "\n",
    "__all__ = make_all(__name__)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between [`tf.layers`](https://www.tensorflow.org/api_docs/python/tf/layers) and [`tf.contrib.layers`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers)\n",
    "\n",
    "#### [`tf.layers.conv2d()`](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)\n",
    "```python\n",
    "tf.layers.conv2d(\n",
    "    inputs,\n",
    "    filters,\n",
    "    kernel_size,\n",
    "    strides=(1, 1),\n",
    "    padding='valid',\n",
    "    data_format='channels_last',\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer=None,\n",
    "    bias_initializer=tf.zeros_initializer(),\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    trainable=True,\n",
    "    name=None,\n",
    "    reuse=None\n",
    ")\n",
    "```\n",
    "\n",
    "#### [`slim.conv2d()`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/conv2d)\n",
    "```python\n",
    "tf.contrib.layers.conv2d(\n",
    "    inputs,\n",
    "    num_outputs,\n",
    "    kernel_size,\n",
    "    stride=1,\n",
    "    padding='SAME',\n",
    "    data_format=None,\n",
    "    rate=1,\n",
    "    activation_fn=tf.nn.relu,\n",
    "    normalizer_fn=None,\n",
    "    normalizer_params=None,\n",
    "    weights_initializer=initializers.xavier_initializer(),\n",
    "    weights_regularizer=None,\n",
    "    biases_initializer=tf.zeros_initializer(),\n",
    "    biases_regularizer=None,\n",
    "    reuse=None,\n",
    "    variables_collections=None,\n",
    "    outputs_collections=None,\n",
    "    trainable=True,\n",
    "    scope=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(x):\n",
    "  \"\"\"Model function for CNN.\n",
    "  Args:\n",
    "    x: input images\n",
    "    mode: boolean whether trainig mode or test mode\n",
    "    \n",
    "  Returns:\n",
    "    logits: unnormalized score funtion\n",
    "  \"\"\"\n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  # MNIST images are 28x28 pixels, and have one color channel\n",
    "  with tf.name_scope('reshape'):\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "  # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  conv1 = slim.conv2d(x_image, 32, [5, 5], scope='conv1')\n",
    "  #conv1 = tf.layers.conv2d(\n",
    "  #    inputs=x_image,\n",
    "  #    filters=32,\n",
    "  #    kernel_size=[5, 5],\n",
    "  #    padding=\"same\",\n",
    "  #    activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  pool1 = slim.max_pool2d(conv1, [2, 2], scope='pool1')\n",
    "  #pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "  \n",
    "  # Convolutional Layer #2\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  conv2 = slim.conv2d(pool1, 64, [5, 5], scope='conv2')\n",
    "\n",
    "  # Pooling Layer #2\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  pool2 = slim.max_pool2d(conv2, [2, 2], scope='pool2')\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  pool2_flat = slim.flatten(pool2, scope='flatten')\n",
    "  \n",
    "  # Fully connected Layer\n",
    "  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "  fc1 = slim.fully_connected(pool2_flat, 1024, scope='fc1')\n",
    "  #dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "  is_training = tf.placeholder(tf.bool)\n",
    "  fc1_drop = slim.dropout(fc1, keep_prob=0.6, is_training=is_training, scope='dropout')\n",
    "  #dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=is_training)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 10]\n",
    "  logits = slim.fully_connected(fc1_drop, 10, activation_fn=None, scope='logits')\n",
    "  \n",
    "  return logits, is_training, x_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, is_training, x_image = cnn_model_fn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기를 직접 채워 넣으시면 됩니다.\n",
    "#y_one_hot = tf.one_hot(y, depth=10)\n",
    "#cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=y_one_hot, logits=logits)\n",
    "cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=y,\n",
    "                                                       logits=logits)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign `tf.summary.FileWriter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph to: graphs/02_mnist_cnn_with_slim\n"
     ]
    }
   ],
   "source": [
    "graph_location = 'graphs/02_mnist_cnn_with_slim'\n",
    "print('Saving graph to: %s' % graph_location)\n",
    "train_writer = tf.summary.FileWriter(graph_location)\n",
    "train_writer.add_graph(tf.get_default_graph()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.summary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('summaries'):\n",
    "  tf.summary.scalar('loss/cross_entropy', cross_entropy)\n",
    "  tf.summary.image('images', x_image)\n",
    "  for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.op.name, var)\n",
    "  # merge all summaries\n",
    "  summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.Session()` and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 2.3410348892211914\n",
      "step: 100, loss: 0.671227753162384\n",
      "step: 200, loss: 0.5890415906906128\n",
      "step: 300, loss: 0.1516132652759552\n",
      "step: 400, loss: 0.16379666328430176\n",
      "step: 500, loss: 0.3627617061138153\n",
      "step: 600, loss: 0.1848478764295578\n",
      "step: 700, loss: 0.19724035263061523\n",
      "step: 800, loss: 0.1862480640411377\n",
      "step: 900, loss: 0.1256924867630005\n",
      "step: 1000, loss: 0.0855906680226326\n",
      "step: 1100, loss: 0.11214687675237656\n",
      "step: 1200, loss: 0.09775674343109131\n",
      "step: 1300, loss: 0.10268816351890564\n",
      "step: 1400, loss: 0.20917865633964539\n",
      "step: 1500, loss: 0.12863631546497345\n",
      "step: 1600, loss: 0.21946462988853455\n",
      "step: 1700, loss: 0.07050535082817078\n",
      "step: 1800, loss: 0.017263125628232956\n",
      "End of dataset\n",
      "Epochs: 0 Elapsed time: 1243.0300946235657\n",
      "step: 1900, loss: 0.08405248820781708\n",
      "step: 2000, loss: 0.01173703558743\n",
      "step: 2100, loss: 0.041676782071590424\n",
      "step: 2200, loss: 0.11071394383907318\n",
      "step: 2300, loss: 0.07467187941074371\n",
      "step: 2400, loss: 0.2024710774421692\n",
      "step: 2500, loss: 0.03625354543328285\n",
      "step: 2600, loss: 0.05804820358753204\n",
      "step: 2700, loss: 0.2900006175041199\n",
      "step: 2800, loss: 0.16619078814983368\n",
      "step: 2900, loss: 0.07706372439861298\n",
      "step: 3000, loss: 0.0564555749297142\n",
      "step: 3100, loss: 0.028827236965298653\n",
      "step: 3200, loss: 0.006364574655890465\n",
      "step: 3300, loss: 0.01890505850315094\n",
      "step: 3400, loss: 0.05819956585764885\n",
      "step: 3500, loss: 0.06468312442302704\n",
      "step: 3600, loss: 0.0954645574092865\n",
      "step: 3700, loss: 0.020790327340364456\n",
      "End of dataset\n",
      "Epochs: 1 Elapsed time: 1121.6366057395935\n",
      "training done!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config=sess_config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train_iterator\n",
    "train_iterator = train_dataset.make_initializable_iterator()\n",
    "train_handle = sess.run(train_iterator.string_handle())\n",
    "\n",
    "# Train\n",
    "max_epochs = 2\n",
    "step = 0\n",
    "for epochs in range(max_epochs):\n",
    "  # 여기를 직접 채워 넣으시면 됩니다.\n",
    "  sess.run(train_iterator.initializer)\n",
    "\n",
    "  start_time = time.time()\n",
    "  while True:\n",
    "    try:\n",
    "      # 여기를 직접 채워 넣으시면 됩니다.\n",
    "      _, loss = sess.run([train_step, cross_entropy],\n",
    "                         feed_dict={handle: train_handle,\n",
    "                                    is_training: True})\n",
    "      if step % 100 == 0:\n",
    "        print(\"step: {}, loss: {}\".format(step, loss))\n",
    "        \n",
    "        # summary\n",
    "        summary_str = sess.run(summary_op, feed_dict={handle: train_handle, is_training: False})\n",
    "        train_writer.add_summary(summary_str, global_step=step)\n",
    "        \n",
    "      step += 1\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      print(\"End of dataset\")  # ==> \"End of dataset\"\n",
    "      break\n",
    "    \n",
    "  print(\"Epochs: {} Elapsed time: {}\".format(epochs, time.time() - start_time))\n",
    "\n",
    "train_writer.close()\n",
    "print(\"training done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_iterator\n",
    "test_iterator = test_dataset.make_initializable_iterator()\n",
    "test_handle = sess.run(test_iterator.string_handle())\n",
    "sess.run(test_iterator.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, acc_op = tf.metrics.accuracy(labels=y, predictions=tf.argmax(logits, 1), name='accuracy')\n",
    "sess.run(tf.local_variables_initializer())\n",
    "\n",
    "sess.run(acc_op, feed_dict={handle: test_handle, is_training: False})\n",
    "print(\"test accuracy:\", sess.run(accuracy, feed_dict={handle: test_handle, is_training: False}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "test_batch_size = 16\n",
    "batch_index = np.random.choice(len(test_data), size=test_batch_size, replace=False)\n",
    "batch_xs = test_data[batch_index]\n",
    "y_pred = sess.run(logits, feed_dict={x: batch_xs, is_training: False})\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (px, py) in enumerate(zip(batch_xs, y_pred)):\n",
    "  p = fig.add_subplot(4, 8, i+1)\n",
    "  p.set_title(\"y_pred: {}\".format(np.argmax(py)))\n",
    "  p.imshow(px.reshape(28, 28), cmap='gray')\n",
    "  p.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Program Files\\Anaconda3\\envs\\tensorflow_1_7\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import string\n",
    "%matplotlib inline\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['good', 'bad', 'amazing', 'so good', 'bull shit', 'awesome']\n",
    "y = [[1.,0.], [0.,1.], [1.,0.], [1., 0.],[0.,1.], [1.,0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz *'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Character quantization\n",
    "char_space = string.ascii_lowercase \n",
    "char_space = char_space + ' ' + '*'\n",
    "char_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 23, ' ': 26, 'h': 7, 'g': 6, 's': 18, 'o': 14, 'b': 1, 'i': 8, 'f': 5, 'z': 25, 'n': 13, 'j': 9, 'a': 0, 'p': 15, '*': 27, 'l': 11, 'e': 4, 'y': 24, 'u': 20, 'v': 21, 'w': 22, 't': 19, 'r': 17, 'k': 10, 'd': 3, 'q': 16, 'm': 12, 'c': 2}\n"
     ]
    }
   ],
   "source": [
    "char_dic = {char : idx for idx, char in enumerate(char_space)}\n",
    "print(char_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(sequences, max_len, dic):\n",
    "    seq_len, seq_indices = [], []\n",
    "    for seq in sequences:\n",
    "        seq_len.append(len(seq))\n",
    "        seq_idx = [dic.get(char) for char in seq]\n",
    "        seq_idx += (max_len - len(seq_idx)) * [dic.get('*')] # 27 is idx of meaningless token \"*\"\n",
    "        seq_indices.append(seq_idx)\n",
    "    return seq_len, seq_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 10\n",
    "X_length, X_indices = pad_seq(sequences = words, max_len = max_length, dic = char_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 7, 7, 9, 7]\n",
      "(6, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_length)\n",
    "print(np.shape(X_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharStackedBiRNN:\n",
    "    def __init__(self, X_length, X_indices, y, n_of_classes, hidden_dims, dic):\n",
    "        \n",
    "        with tf.variable_scope('rnn_input_layer'):\n",
    "            self._X_length = X_length\n",
    "            self._X_indices = X_indices\n",
    "            self._y = y\n",
    "            \n",
    "            one_hot = tf.eye(len(dic), dtype=tf.float32)\n",
    "            self._one_hot = tf.get_variable(name='one_hot_embedding', initializer=one_hot,\n",
    "                                           trainable=False)\n",
    "            self._X_batch = tf.nn.embedding_lookup(params=self._one_hot, ids=self._X_indices)\n",
    "            self._keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "            \n",
    "        with tf.variable_scope('stacked_bi_rnn'):\n",
    "            rnn_fw_cells = []\n",
    "            for hidden_dim in hidden_dims:\n",
    "                rnn_fw_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=hidden_dim,activation=tf.nn.tanh)\n",
    "                rnn_fw_cell = tf.nn.rnn_cell.DropoutWrapper(cell=rnn_fw_cell, \n",
    "                                                            output_keep_prob=self._keep_prob)\n",
    "                rnn_fw_cells.append(rnn_fw_cell)\n",
    "            rnn_bw_cells = []\n",
    "            for hidden_dim in hidden_dims:\n",
    "                rnn_bw_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=hidden_dim,activation=tf.nn.tanh)\n",
    "                rnn_bw_cell = tf.nn.rnn_cell.DropoutWrapper(cell=rnn_bw_cell,\n",
    "                                                            output_keep_prob=self._keep_prob)\n",
    "                rnn_bw_cells.append(rnn_bw_cell)\n",
    "                \n",
    "            _, self.output_state_fw, self.output_state_bw = \\\n",
    "            tf.contrib.rnn.stack_bidirectional_dynamic_rnn(cells_fw=rnn_fw_cells, cells_bw=rnn_bw_cells, \n",
    "                                                          inputs=self._X_batch,\n",
    "                                                          sequence_length=self._X_length,\n",
    "                                                          dtype=tf.float32)\n",
    "            # [batch, hidden_unit]으로 최종 state가 나오므로 axis=1로 주어서 hidden_unit을 기준으로 concat\n",
    "            final_state = tf.concat([self.output_state_fw[-1], self.output_state_bw[-1]], axis=1)\n",
    "            \n",
    "        with tf.variable_scope('rnn_output'):\n",
    "            self._score = slim.fully_connected(inputs=final_state, num_outputs=n_of_classes,\n",
    "                                              activation_fn=None)\n",
    "            \n",
    "        with tf.variable_scope('loss'):\n",
    "            self.ce_loss = tf.losses.softmax_cross_entropy(onehot_labels=self._y, logits=self._score)\n",
    "            \n",
    "        with tf.variable_scope('prediction'):\n",
    "            self._prediction = tf.argmax(input=self._score,axis=-1,output_type=tf.int32)\n",
    "            \n",
    "    def predict(self, sess, X_length, X_indices, keep_prob=1.0):\n",
    "        feed_prediction = {self._X_length:X_length, self._X_indices:X_indices, self._keep_prob:keep_prob}\n",
    "        return sess.run(self._prediction, feed_dict=feed_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "char_stacked_bi_rnn.output_state_bw\n",
    "\n",
    "(<tf.Tensor 'stacked_bi_rnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 16) dtype=float32>,\n",
    " <tf.Tensor 'stacked_bi_rnn/stack_bidirectional_rnn/cell_1/bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 16) dtype=float32>)\n",
    "\n",
    "\n",
    "char_stacked_bi_rnn.output_state_fw\n",
    "(<tf.Tensor 'stacked_bi_rnn/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 16) dtype=float32>,\n",
    " <tf.Tensor 'stacked_bi_rnn/stack_bidirectional_rnn/cell_1/bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 16) dtype=float32>)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharStackedBiLSTM:\n",
    "    def __init__(self, X_length, X_indices, y, n_of_classes, hidden_dims, dic):\n",
    "        \n",
    "        # data pipeline\n",
    "        with tf.variable_scope('input_layer'):\n",
    "            self._X_length = X_length\n",
    "            self._X_indices = X_indices\n",
    "            self._y = y\n",
    "            \n",
    "            one_hot = tf.eye(len(dic), dtype = tf.float32)\n",
    "            self._one_hot = tf.get_variable(name='one_hot_embedding', initializer = one_hot,\n",
    "                                            trainable = False) # embedding vector training 안할 것이기 때문\n",
    "            self._X_batch = tf.nn.embedding_lookup(params = self._one_hot, ids = self._X_indices)\n",
    "            self._keep_prob = tf.placeholder(dtype = tf.float32)\n",
    "        \n",
    "        # Stacked Bi-directional LSTM with Drop out\n",
    "        with tf.variable_scope('stacked_bi-directional_lstm'):\n",
    "            \n",
    "            # forward \n",
    "            lstm_fw_cells = []\n",
    "            for hidden_dim in hidden_dims:\n",
    "                lstm_fw_cell = tf.nn.rnn_cell.BasicRNNCell(num_units = hidden_dim, activation = tf.nn.tanh)\n",
    "                lstm_fw_cell = tf.nn.rnn_cell.DropoutWrapper(cell = lstm_fw_cell,\n",
    "                                                             output_keep_prob = self._keep_prob)\n",
    "                lstm_fw_cells.append(lstm_fw_cell)\n",
    "            \n",
    "            # backword\n",
    "            lstm_bw_cells = []\n",
    "            for hidden_dim in hidden_dims:\n",
    "                lstm_bw_cell = tf.nn.rnn_cell.BasicRNNCell(num_units = hidden_dim, activation = tf.nn.tanh)\n",
    "                lstm_bw_cell = tf.nn.rnn_cell.DropoutWrapper(cell = lstm_bw_cell,\n",
    "                                                             output_keep_prob = self._keep_prob)\n",
    "                lstm_bw_cells.append(lstm_bw_cell)\n",
    "            \n",
    "            _, self.output_state_fw, self.output_state_bw = \\\n",
    "            tf.contrib.rnn.stack_bidirectional_dynamic_rnn(cells_fw = lstm_fw_cells, cells_bw = lstm_bw_cells,\n",
    "                                                           inputs = self._X_batch,\n",
    "                                                           sequence_length = self._X_length,\n",
    "                                                           dtype = tf.float32)\n",
    "\n",
    "            final_state = tf.concat([self.output_state_fw[-1], self.output_state_bw[-1]], axis = 1)\n",
    "\n",
    "        with tf.variable_scope('output_layer'):\n",
    "            self._score = slim.fully_connected(inputs = final_state, num_outputs = n_of_classes,\n",
    "                                               activation_fn = None)\n",
    "            \n",
    "        with tf.variable_scope('loss'):\n",
    "            self.ce_loss = tf.losses.softmax_cross_entropy(onehot_labels = self._y, logits = self._score)\n",
    "            \n",
    "        with tf.variable_scope('prediction'):\n",
    "            self._prediction = tf.argmax(input = self._score, axis = -1, output_type = tf.int32)\n",
    "    \n",
    "    def predict(self, sess, X_length, X_indices, keep_prob = 1.):\n",
    "        feed_prediction = {self._X_length : X_length, self._X_indices : X_indices, self._keep_prob : keep_prob}\n",
    "        return sess.run(self._prediction, feed_dict = feed_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "char_stacked_bi_rnn.output_state_fw\n",
    "\n",
    "(<tf.Tensor 'stacked_bi-directional_lstm/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 16) dtype=float32>,\n",
    " <tf.Tensor 'stacked_bi-directional_lstm/stack_bidirectional_rnn/cell_1/bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 16) dtype=float32>)\n",
    "\n",
    "char_stacked_bi_rnn.output_state_bw\n",
    "(<tf.Tensor 'stacked_bi-directional_lstm/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 16) dtype=float32>,\n",
    " <tf.Tensor 'stacked_bi-directional_lstm/stack_bidirectional_rnn/cell_1/bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 16) dtype=float32>)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharStackBiGRU:\n",
    "    def __init__(self, X_length, X_indices, y, n_of_classes, hidden_dims, dic):\n",
    "        \n",
    "        with tf.variable_scope('gru_input'):\n",
    "            self._X_length = X_length\n",
    "            self._X_indices = X_indices\n",
    "            self._y = y\n",
    "            \n",
    "            one_hot = tf.eye(len(dic), dtype=tf.float32)\n",
    "            self._one_hot = tf.get_variable(name='one_hot_embedding', initializer=one_hot,\n",
    "                                           trainable = False)\n",
    "            self._X_batch = tf.nn.embedding_lookup(params=self._one_hot, ids=self._X_indices)\n",
    "            self._keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "            \n",
    "        with tf.variable_scope('stacked_bi_gru'):\n",
    "            \n",
    "            gru_fw_cells = []\n",
    "            for hidden_dim in hidden_dims:\n",
    "                gru_fw_cell = tf.nn.rnn_cell.GRUCell(num_units=hidden_dim,activation=tf.nn.tanh)\n",
    "                gru_fw_cell = tf.nn.rnn_cell.DropoutWrapper(cell=gru_fw_cell,output_keep_prob=self._keep_prob)\n",
    "                gru_fw_cells.append(gru_fw_cell)\n",
    "                \n",
    "            gru_bw_cells = []\n",
    "            for hidden_dim in hidden_dims:\n",
    "                gru_bw_cell = tf.nn.rnn_cell.GRUCell(num_units=hidden_dim,activation=tf.nn.tanh)\n",
    "                gru_bw_cell = tf.nn.rnn_cell.DropoutWrapper(cell=gru_bw_cell,output_keep_prob=self._keep_prob)\n",
    "                gru_bw_cells.append(gru_bw_cell)\n",
    "            \n",
    "            _, self.output_state_fw, self.output_state_bw = \\\n",
    "            tf.contrib.rnn.stack_bidirectional_dynamic_rnn(cells_fw = gru_fw_cells, cells_bw = gru_bw_cells,\n",
    "                                                           inputs = self._X_batch,\n",
    "                                                           sequence_length = self._X_length,\n",
    "                                                           dtype = tf.float32)\n",
    "            \n",
    "            final_state = tf.concat([self.output_state_fw[-1], self.output_state_bw[-1]], axis=1)\n",
    "            \n",
    "        with tf.variable_scope('gur_output'):\n",
    "            self._score = slim.fully_connected(inputs=final_state,num_outputs=n_of_classes,activation_fn=None)\n",
    "            \n",
    "        with tf.variable_scope('gru_loss'):\n",
    "            self.ce_loss = tf.losses.softmax_cross_entropy(onehot_labels=self._y, logits=self._score)\n",
    "            \n",
    "        with tf.variable_scope('gru_prediction'):\n",
    "            self._prediction = tf.argmax(input=self._score, axis=-1, output_type=tf.int32)\n",
    "            \n",
    "    def predict(self, sess, X_length, X_indices, keep_prob=1.0):\n",
    "        feed_prediction={self._X_length:X_length, self._X_indices:X_indices, self._keep_prob:keep_prob}\n",
    "        return sess.run(self._prediction, feed_dict=feed_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "char_stacked_bi_rnn.output_state_bw\n",
    "\n",
    "(<tf.Tensor 'stacked_bi_gru/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 16) dtype=float32>,\n",
    " <tf.Tensor 'stacked_bi_gru/stack_bidirectional_rnn/cell_1/bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 16) dtype=float32>)\n",
    "\n",
    "char_stacked_bi_rnn.output_state_fw\n",
    "(<tf.Tensor 'stacked_bi_gru/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 16) dtype=float32>,\n",
    " <tf.Tensor 'stacked_bi_gru/stack_bidirectional_rnn/cell_1/bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 16) dtype=float32>)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "lr = 0.003\n",
    "epochs = 10\n",
    "batch_size = 2\n",
    "total_step = int(np.shape(X_indices)[0] / batch_size)\n",
    "print(total_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = tf.data.Dataset.from_tensor_slices((X_length, X_indices, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((?,), (?, 10), (?, 2)), types: (tf.int32, tf.int32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "tr_dataset = tr_dataset.shuffle(buffer_size=20)\n",
    "tr_dataset = tr_dataset.batch(batch_size=batch_size)\n",
    "tr_iterator = tr_dataset.make_initializable_iterator()\n",
    "print(tr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_length_mb, X_indices_mb, y_mb = tr_iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_stacked_bi_rnn = CharStackBiGRU(X_length=X_length_mb, X_indices=X_indices_mb,\n",
    "                                      y=y_mb, n_of_classes=2, hidden_dims=[16,16], dic=char_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "training_op = opt.minimize(char_stacked_bi_rnn.ce_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   1, tr_loss: 1.106\n",
      "epoch :   2, tr_loss: 0.680\n",
      "epoch :   3, tr_loss: 0.651\n",
      "epoch :   4, tr_loss: 0.433\n",
      "epoch :   5, tr_loss: 0.414\n",
      "epoch :   6, tr_loss: 0.368\n",
      "epoch :   7, tr_loss: 0.288\n",
      "epoch :   8, tr_loss: 0.200\n",
      "epoch :   9, tr_loss: 0.165\n",
      "epoch :  10, tr_loss: 0.190\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "tr_loss_hist = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_tr_loss = 0\n",
    "    tr_step = 0\n",
    "    \n",
    "    sess.run(tr_iterator.initializer)\n",
    "    try:\n",
    "        while True:\n",
    "            _, tr_loss = sess.run([training_op, char_stacked_bi_rnn.ce_loss],\n",
    "                                 feed_dict={char_stacked_bi_rnn._keep_prob : 0.5})\n",
    "            avg_tr_loss += tr_loss\n",
    "            tr_step +=1\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "    \n",
    "    avg_tr_loss /= tr_step\n",
    "    tr_loss_hist.append(avg_tr_loss)\n",
    "    \n",
    "    print('epoch : {:3}, tr_loss: {:.3f}'.format(epoch+1, avg_tr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15d5fa3ac18>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_loss_hist, label='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = char_stacked_bi_rnn.predict(sess, X_length, X_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainign acc:100.00%\n"
     ]
    }
   ],
   "source": [
    "print('trainign acc:{:.2%}'.format(np.mean(yhat==np.argmax(y, axis=-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

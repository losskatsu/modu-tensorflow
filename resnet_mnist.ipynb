{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shatapy/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "                        tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "train_data = train_data / 255.\n",
    "train_labels = np.asarray(train_labels, dtype=np.int32)\n",
    "\n",
    "test_data = test_data / 255.\n",
    "test_labels = np.asarray(test_labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "train_dataset = train_dataset.shuffle(10000)\n",
    "train_dataset = train_dataset.batch(batch_size=batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "test_dataset = test_dataset.shuffle(buffer_size = 10000)\n",
    "test_dataset = test_dataset.batch(batch_size = len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(handle,\n",
    "                                              train_dataset.output_types,\n",
    "                                              train_dataset.output_shapes)\n",
    "\n",
    "x, y = iterator.get_next()\n",
    "x = tf.cast(x, tf.float32)\n",
    "y = tf.cast(y, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_block(x, output_channel, is_training=True, down_sampling=False, is_end=False):\n",
    "    \n",
    "    if down_sampling:\n",
    "        stride = 2\n",
    "    else:\n",
    "        stride = 1\n",
    "    \n",
    "    h1 = slim.conv2d(x, output_channel, [3, 3], stride=stride, activation_fn=None)\n",
    "    h1 = tf.layers.batch_normalization(h1, training=is_training)\n",
    "    h1 = tf.nn.relu(h1)\n",
    "    \n",
    "    h2 = slim.conv2d(h1, output_channel, [3, 3], stride=1, activation_fn=None)\n",
    "    h2 = tf.layers.batch_normalization(h2, training=is_training)\n",
    "\n",
    "    if down_sampling:\n",
    "        x = slim.conv2d(x, output_channel, [1, 1], stride=stride, activation_fn=None)\n",
    "    \n",
    "    if is_end:\n",
    "        return h2 + x\n",
    "    return tf.nn.relu(h2 + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_resnet(x, layer_n):\n",
    "    x = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    \n",
    "    with tf.variable_scope('conv0'):\n",
    "        net = slim.conv2d(x, 16, [3, 3], activation_fn=None)\n",
    "        net = tf.layers.batch_normalization(net, training=is_training)\n",
    "        net = tf.nn.relu(net)\n",
    "        \n",
    "    with tf.variable_scope('res0'):\n",
    "        for i in range(layer_n):\n",
    "            net = residual_block(net, 16, is_training)\n",
    "    \n",
    "    with tf.variable_scope('res1'):\n",
    "        for i in range(layer_n):\n",
    "            net = residual_block(net, 32, is_training, down_sampling=(i==0))\n",
    "            \n",
    "    with tf.variable_scope('res2'):\n",
    "        for i in range(layer_n):\n",
    "            net = residual_block(net, 64, is_training, down_sampling=(i==0), is_end=(i==layer_n-1))\n",
    "            \n",
    "    with tf.variable_scope('fc'):\n",
    "        net = slim.flatten(net)\n",
    "        net = slim.fully_connected(net, 10, activation_fn=None)\n",
    "        \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_training = tf.placeholder(tf.bool)\n",
    "logits = build_resnet(x, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_one_hot = tf.one_hot(y, 10)\n",
    "loss = tf.losses.softmax_cross_entropy(logits=logits, onehot_labels=y_one_hot)\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('summaries'):\n",
    "  tf.summary.scalar('loss/cross_entropy', loss)\n",
    "  for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.op.name, var)\n",
    "  # merge all summaries\n",
    "  summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph to: graphs/resnet_mnist\n"
     ]
    }
   ],
   "source": [
    "graph_location = 'graphs/resnet_mnist'\n",
    "print('Saving graph to: %s' % graph_location)\n",
    "train_writer = tf.summary.FileWriter(graph_location)\n",
    "train_writer.add_graph(tf.get_default_graph()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Loss: 4.35556\n",
      "Step: 100, Loss: 0.0524195\n",
      "Step: 200, Loss: 0.00833457\n",
      "Step: 300, Loss: 0.157783\n",
      "Step: 400, Loss: 0.0402068\n",
      "Step: 500, Loss: 0.214297\n",
      "Step: 600, Loss: 0.0206651\n",
      "Step: 700, Loss: 0.148918\n",
      "Step: 800, Loss: 0.0167361\n",
      "Step: 900, Loss: 0.0724524\n",
      "Step: 1000, Loss: 0.12014\n",
      "Step: 1100, Loss: 0.00613719\n",
      "Step: 1200, Loss: 0.110616\n",
      "Step: 1300, Loss: 0.00250984\n",
      "Step: 1400, Loss: 0.00182672\n",
      "Step: 1500, Loss: 0.000624037\n",
      "Step: 1600, Loss: 0.0322433\n",
      "Step: 1700, Loss: 0.146266\n",
      "Step: 1800, Loss: 0.133401\n",
      "End of dataset\n",
      "Epoch:  0\n",
      "Step: 1900, Loss: 0.0291083\n",
      "Step: 2000, Loss: 0.379921\n",
      "Step: 2100, Loss: 0.11385\n",
      "Step: 2200, Loss: 0.176421\n",
      "Step: 2300, Loss: 0.00892418\n",
      "Step: 2400, Loss: 0.152084\n",
      "Step: 2500, Loss: 0.00242565\n",
      "Step: 2600, Loss: 0.000161772\n",
      "Step: 2700, Loss: 0.0913321\n",
      "Step: 2800, Loss: 0.0214422\n",
      "Step: 2900, Loss: 0.0286437\n",
      "Step: 3000, Loss: 0.145241\n",
      "Step: 3100, Loss: 0.00484136\n",
      "Step: 3200, Loss: 0.0409748\n",
      "Step: 3300, Loss: 0.0313218\n",
      "Step: 3400, Loss: 0.133874\n",
      "Step: 3500, Loss: 0.00525874\n",
      "Step: 3600, Loss: 0.00268365\n",
      "Step: 3700, Loss: 0.000387135\n",
      "End of dataset\n",
      "Epoch:  1\n",
      "Training done!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_iterator = train_dataset.make_initializable_iterator()\n",
    "train_handle = sess.run(train_iterator.string_handle())\n",
    "\n",
    "epochs = 2\n",
    "step = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    sess.run(train_iterator.initializer)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            _, loss_ = sess.run([train_op, loss], \n",
    "                                feed_dict={handle: train_handle, is_training: True})\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                print(\"Step: %d, Loss: %g\" % (step, loss_))\n",
    "                \n",
    "                summary_str = sess.run(summary_op, \n",
    "                                      feed_dict={handle: train_handle, is_training: True})\n",
    "                train_writer.add_summary(summary_str, global_step=step)\n",
    "            \n",
    "            step += 1\n",
    "            \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('End of dataset')\n",
    "            break\n",
    "        \n",
    "    print('Epoch: ', epoch)\n",
    "\n",
    "train_writer.close()\n",
    "print('Training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_iterator = test_dataset.make_initializable_iterator()\n",
    "test_handle = sess.run(test_iterator.string_handle())\n",
    "sess.run(test_iterator.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.9864\n"
     ]
    }
   ],
   "source": [
    "accuracy, acc_op = tf.metrics.accuracy(labels=y, predictions=tf.argmax(logits, 1), name='accuracy')\n",
    "sess.run(tf.local_variables_initializer())\n",
    "\n",
    "sess.run(acc_op, feed_dict={handle: test_handle, is_training: True})\n",
    "print(\"test accuracy:\", sess.run(accuracy, feed_dict={handle: test_handle, is_training: True}))"
   ]
  },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
